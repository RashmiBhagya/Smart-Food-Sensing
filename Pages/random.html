<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Our Research</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f4f4f4;
            margin: 0;
            padding: 0;
        }
        .container {
            width: 80%;
            margin: 0 auto;
            padding: 20px;
        }
        .main-title {
            text-align: center;
            font-size: 2.5em;
            margin-bottom: 20px;
            color: #333;
        }
        .main-title span {
            color: #007BFF;
        }
        .main-photo {
            display: block;
            max-width: 60%;
            height: auto;
            margin: 0 auto;
            border-radius: 10px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }
        .paragraph {
            text-align: justify;
            margin: 20px 0;
            font-size: 1.1em;
            color: #555;
        }
        .cta {
            display: block;
            width: fit-content;
            margin: 20px auto;
            padding: 10px 20px;
            background-color: #007BFF;
            color: white;
            text-decoration: none;
            border-radius: 5px;
            text-align: center;
        }
        .cta:hover {
            background-color: #0056b3;
        }
        .card-container {
            display: flex;
            flex-wrap: wrap;
            justify-content: space-between;
            gap: 20px;
            margin-top: 20px;
        }
        .card {
            background: white;
            border-radius: 10px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
            overflow: hidden;
            width: calc(33% - 20px);
            display: flex;
            flex-direction: column;
            align-items: center;
            text-align: center;
        }
        .card img {
            width: 100%;
            height: auto;
        }
        .card-title {
            font-size: 1.2em;
            margin: 10px 0;
            color: #333;
        }
        .card p {
            font-size: 0.9em;
            color: #666;
            padding: 0 10px 10px;
        }
        .image-container {
            justify-content: space-between;
            gap: 20px;
            margin-top: 20px;
        }
        .image-container img {
            width: 20%;
            border-radius: 10px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }
    </style>
</head>
<body>
    <div class="container">
        <h1 class="main-title">REAL-TIME <span> VISUAL INSPECTION SYSTEM FOR GRADING FRUITS</span></h1>
        <img src="../img/random.png" alt="Main Research Image" class="main-photo">
        <p class="paragraph">
                The agriculture sector is a cornerstone of economies globally, with fresh fruit production and supply playing a crucial role. However, the efficiency and productivity of fruit grading and sorting activities remain key difficulties. Traditional manual grading methods, highly reliant on human labor and visual examination, are not only time-consuming but also prone to irregularities and errors. Moreover, the increased need for timely market delivery necessitates faster and more precise grading processes. In response to these obstacles, researchers and practitioners have turned to cutting-edge technologies, particularly in the fields of computer vision and machine learning, to automate and streamline fruit grading operations.
                Despite the achievements made in employing technology for fruit grading, some fundamental problems exist, comprising the research subject at hand. One such difficulty is the reliance on hand-crafted feature extraction approaches in present grading systems. These strategies often require manually defining and extracting attributes such as color, texture, and form descriptors from fruit photos. While useful to some level, hand-crafted features are intrinsically restricted in their capacity to portray the numerous and complex
                18
                properties of different fruit species. This constraint not only limits the accuracy of grading outcomes but also makes the system less flexible to differences in fruit appearance.
                Furthermore, the lack of generalizability across different fruit species provides a substantial hurdle to the broad implementation of automated grading systems. Many existing models are geared to certain fruit varieties and may struggle to appropriately grade fruits with diverse forms, colors, or surface textures. This lack of adaptability inhibits the usefulness of automated grading systems, particularly for small-scale agricultural enterprises and individual farmers who may grow a range of fruits.
                Addressing these difficulties is critical for enhancing the efficiency, reliability, and accessibility of fruit grading devices. A robust and scalable automated grading system is needed to decrease human labor, reduce grading time, and increase grading accuracy across varied fruit kinds. Additionally, such a system should be adaptive and diverse enough to accept differences in fruit look and features.
                Therefore, the research challenge revolves around constructing a deep learning-based automated fruit grading system that overcomes the constraints of previous hand-crafted feature extraction methodologies. This system should be capable of accurately grading numerous fruit varieties in real-time, without the need for considerable operator intervention or calibration. By solving these problems, the project intends to pave the way for more efficient and cost-effective fruit grading operations, benefiting agricultural stakeholders ranging from small-scale farmers to large-scale producers and distributors.
       </p>
       
</body>
</html>